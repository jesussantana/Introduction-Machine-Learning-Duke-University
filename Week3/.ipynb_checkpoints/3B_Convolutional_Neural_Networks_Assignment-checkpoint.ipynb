{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Assignment: Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Duke Community Standard](http://integrity.duke.edu/standard.html): By typing your name below, you are certifying that you have adhered to the Duke Community Standard in completing this assignment.**\n",
    "\n",
    "Name: Abhinav Tembulkar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network\n",
    "\n",
    "Adapt the CNN example for MNIST digit classfication from Notebook 3A. \n",
    "Feel free to play around with the model architecture and see how the training time/performance changes, but to begin, try the following:\n",
    "\n",
    "Image ->  \n",
    "convolution (32 3x3 filters) -> nonlinearity (ReLU) ->  \n",
    "convolution (32 3x3 filters) -> nonlinearity (ReLU) -> (2x2 max pool) ->  \n",
    "convolution (64 3x3 filters) -> nonlinearity (ReLU) ->  \n",
    "convolution (64 3x3 filters) -> nonlinearity (ReLU) -> (2x2 max pool) -> flatten ->\n",
    "fully connected (256 hidden units) -> nonlinearity (ReLU) ->  \n",
    "fully connected (10 hidden units) -> softmax \n",
    "\n",
    "Note: The CNN model might take a while to train. Depending on your machine, you might expect this to take up to half an hour. If you see your validation performance start to plateau, you can kill the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./dataset/MNIST/raw/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 503: Service Unavailable\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./dataset/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81a2281218964773912cf0b65f4907cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=9912422.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting ./dataset/MNIST/raw/train-images-idx3-ubyte.gz to ./dataset/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./dataset/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd5e9d49232547929aaeaeaca598efef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=28881.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting ./dataset/MNIST/raw/train-labels-idx1-ubyte.gz to ./dataset/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./dataset/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "015111d5cd204eb4bec06673d48521d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1648877.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting ./dataset/MNIST/raw/t10k-images-idx3-ubyte.gz to ./dataset/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96f594ebe3604e57ab2bae6b509d1855",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=4542.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting ./dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./dataset/MNIST/raw\n",
      "\n",
      "Processing...\n",
      "Done!\n",
      "running on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jesus/anaconda3/lib/python3.8/site-packages/torchvision/datasets/mnist.py:502: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69500cd027a94a0eaa128df62162790d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=600.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "from torchvision import datasets,transforms\n",
    "import torch.optim as optim\n",
    "\n",
    "trainset = datasets.MNIST(download=True,train=True,root='./dataset',transform=transforms.ToTensor())\n",
    "testset = datasets.MNIST(download=True,train=False,root='./dataset',transform=transforms.ToTensor())\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset,batch_size=100,shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset,batch_size=100,shuffle=False)\n",
    "\n",
    "class CNN_NEW(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.conv1 = nn.Conv2d(1,32,kernel_size=3)\n",
    "    self.conv2 = nn.Conv2d(32,32,kernel_size=3)\n",
    "    self.conv3 = nn.Conv2d(32,64,kernel_size=3)\n",
    "    self.conv4 = nn.Conv2d(64,64,kernel_size=3)\n",
    "    self.fc1 = nn.Linear(20736,256)\n",
    "    self.fc2 = nn.Linear(256,10)\n",
    "\n",
    "  def forward(self,X):\n",
    "    X = F.relu(self.conv1(X))\n",
    "    X = F.relu(self.conv2(X))\n",
    "    max_pool = nn.MaxPool2d(2,1)\n",
    "    X = max_pool(X)\n",
    "    X = F.relu(self.conv3(X))\n",
    "    X = F.relu(self.conv4(X))\n",
    "    X = max_pool(X)\n",
    "    #print(X.flatten().shape)\n",
    "    X = self.fc1(X.view(100,20736))\n",
    "    X = self.fc2(X)\n",
    "    #print(X.shape)\n",
    "    #return F.softmax(X,dim=1)\n",
    "    return X\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  device = torch.device('cuda:0')\n",
    "  print('running on gpu')\n",
    "else:\n",
    "  device = torch.device('cpu')\n",
    "  print('running on cpu')\n",
    "    \n",
    "mymodel = CNN_NEW().to(device)\n",
    "\n",
    "BATCH_SIZE=100\n",
    "EPOCHS=3\n",
    "\n",
    "optimizer = optim.Adam(mymodel.parameters(),lr=0.001)\n",
    "Loss = nn.CrossEntropyLoss()\n",
    "\n",
    "batches = iter(trainloader)\n",
    "\n",
    "for e in range(EPOCHS):\n",
    "  for batch in tqdm(batches):\n",
    "    mymodel.zero_grad()\n",
    "    image, label = batch\n",
    "    image = image.to(device)\n",
    "    label = label.to(device)\n",
    "    #print(image.shape)\n",
    "\n",
    "    Y = mymodel(image)\n",
    "    #print(Y.shape,label.shape)\n",
    "    loss = Loss(Y,label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "  batches = iter(trainloader)\n",
    "\n",
    "tests = iter(testloader)\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "  for batch in tqdm(tests):\n",
    "    img, lbl = batch\n",
    "    imag = img.to(device)\n",
    "    lbl = lbl.to(device)\n",
    "    Y = mymodel(imag)\n",
    "    predict = torch.argmax(Y,dim=1)\n",
    "    \n",
    "#   plt.imshow(img[1].view(28,28))\n",
    "#    plt.title(Y)\n",
    "\n",
    "    for p,l in zip(predict,lbl):\n",
    "      #print(predict,lbl)\n",
    "      if p == l:\n",
    "        correct+=1\n",
    "      total+=1\n",
    "\n",
    "print(\"Accuracy: {}%\".format((correct/total)*100))\n",
    "#print(correct,total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Short answer\n",
    "\n",
    "1\\. How does the CNN compare in accuracy with yesterday's logistic regression and MLP models? How about training time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN has a greater accuracy as compared to MLP and linear regression models.The order of accuracy is as follows:\n",
    "CNN(98.8%) > Linear regression(90.13%) > MLP(82.8%).\n",
    "However, CNN takes the most training time out of all these models.The order of Training time is as follows:\n",
    "CNN > MLP >Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. How many trainable parameters are there in the CNN you built for this assignment?\n",
    "\n",
    "*Note: The total of trainable parameters counts each element in a tensor. For example, a weight matrix that is 10x5 has 50 trainable parameters.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5376234 is total no. of trainable parameters in our CNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. When would you use a CNN versus a logistic regression model or an MLP?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a CNN model over MLP or Linear regression model when we are dealing with image data,as CNN model gives very accurate results in case of image data analysis. We can also use CNN models when we are dealing with complicated classification problems which are beyond the capacity of a MLP or Linear regression model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
